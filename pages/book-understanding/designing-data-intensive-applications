1. Foundation of data systems
    1.1. Reliability, Scalability, Maintainability

        - The problems are the amount of data, the complexity of data, and the speed at which it is changing

        - Data system (Data intensive system) operations:
            + Store data (databases)
            + Remember the result of an expensive operation, to speed up reads (caches)
            + Search by keyword or filter in various ways (search indexes)
            + Send a message to another process, to be handled asynchronously (stream processing)
            + Periodically crunch a large amount of accumulated data (batch processing)

        - Many applications have such demanding or wide-ranging requirements that a single data tool can no longer meet all of needs => Difference data tools (components) are combined together using application code to handle the job (Figure 1-1)

        - Dependencies of data system designing:
            + Skils and experience of people involved
            + Legacy system dependencies
            + Time for delivery
            + Organizationâ€™s tolerance of different kinds of risk
            + Regulatory constraints

        - Reliability: A Fault-tolerant System
            + We have 2 approaches to increase fault tolerance of system:
                . Increase the rate of faults by triggering them deliberately (The Netflix Chaos Monkey is an example of this approach) => This approach is usually used to handle faults which can be cured
                . Prevent the faults (security faults, ...) => This approach is used to handle faults which can be cured (because no curse exists)

            + Faults that can be cured:
                . Hardware Faults:
                    - Hard disks have mean time to failure (MTTF) of about 10 to 50 years.
                    - Hardware faults are isolated faults. Only one or many disks and/or rams could be broken at the same time, not all of them.
                
                . Software Faults:
                    - Software faults are systematic error (the fault is not isolated between each part). The faults are usually correlated across nodes 

                . Human Errors:


        - Scalability:
            + Describe the Load
                . Describe Load by finding key load parameters base on the system architecture.
            + Measure Performance Metrics
                . Find the performance index (how the system effected when the LOAD PARAMETERS increased) such as THROUGHPUT in batch processing system, RESPONSE TIME in online system.
                . Percentiles are often used in service level objectives (SLOs) and service level agreements (SLAs), contracts that define the expected
                . tail latency amplification in microservices
                . Can use FORWARD DECAY, T-DIGEST, HDRHISTOGRAM, ... algorithms to calculate a good approximation of percentiles at minimal CPU and memory cost.
            + Coping with Load
                . Shared-nothing Architecture: Distributing load across multiple machines
                . 

        - Maintainability:





    1.2. Data Models and Query Languages

    1.3. Storage and Retrieval

    1.4. Encoding and Revolution